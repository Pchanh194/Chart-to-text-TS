{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-29 23:50:02\n",
      "2023-08-01 00:00:02\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# Chuyển đổi Unix timestamp sang định dạng ngày/giờ\n",
    "def convert_unix_to_readable(unix_timestamp):\n",
    "    return datetime.utcfromtimestamp(unix_timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "# Ví dụ với dấu thời gian 1696896002.0 và 1696897202.0\n",
    "timestamp1 = 1701301802.0\n",
    "timestamp2 = 1690848002.0\n",
    "\n",
    "readable_time1 = convert_unix_to_readable(timestamp1)\n",
    "readable_time2 = convert_unix_to_readable(timestamp2)\n",
    "\n",
    "print(readable_time1)  # In thời gian dễ hiểu của timestamp1\n",
    "print(readable_time2)  # In thời gian dễ hiểu của timestamp2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chuyển đổi file JSON sang CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['schedule', 'oa_temp', 'room_temp', 'slab_temp', 'dew_temp', 'fan_stat', 'room_sp_value', 'room_sp_range', 'slab_sp_value', 'slab_sp_range', 'thermal_comfort_data', 'issues_count', 'potential_savings']),\n",
       " dict,\n",
       " {'schedule': dict,\n",
       "  'oa_temp': dict,\n",
       "  'room_temp': dict,\n",
       "  'slab_temp': dict,\n",
       "  'dew_temp': dict,\n",
       "  'fan_stat': dict,\n",
       "  'room_sp_value': str,\n",
       "  'room_sp_range': str,\n",
       "  'slab_sp_value': str,\n",
       "  'slab_sp_range': str,\n",
       "  'thermal_comfort_data': dict,\n",
       "  'issues_count': dict,\n",
       "  'potential_savings': dict})"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Đọc và phân tích cấu trúc file JSON:\n",
    "\n",
    "import json\n",
    "\n",
    "# Đọc file JSON\n",
    "file_path = '../dataset/final_merged_data.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    json_data = json.load(file)\n",
    "\n",
    "# Hiển thị cấu trúc của file JSON\n",
    "json_data.keys(), type(json_data), {key: type(json_data[key]) for key in json_data.keys()}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Monday': ['08:00', '17:00'],\n",
       " 'Tuesday': ['08:00', '17:00'],\n",
       " 'Wednesday': ['08:00', '17:00'],\n",
       " 'Thursday': ['08:00', '17:00'],\n",
       " 'Friday': ['08:00', '17:00'],\n",
       " 'Saturday': ['08:00', '17:00'],\n",
       " 'Sunday': ['08:00', '17:00'],\n",
       " 'Public Holiday': ['08:00', '17:00']}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Kiểm tra cấu trúc của một trong các dictionary con:\n",
    "\n",
    "example_key = 'schedule'\n",
    "json_data[example_key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('schedule_Monday', ['08:00', '17:00']),\n",
       " ('schedule_Tuesday', ['08:00', '17:00']),\n",
       " ('schedule_Wednesday', ['08:00', '17:00']),\n",
       " ('schedule_Thursday', ['08:00', '17:00']),\n",
       " ('schedule_Friday', ['08:00', '17:00'])]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Chuẩn bị hàm để làm phẳng dữ liệu JSON:\n",
    "\n",
    "def flatten_json(json_obj):\n",
    "    flattened_data = {}\n",
    "    for key, value in json_obj.items():\n",
    "        if isinstance(value, dict):\n",
    "            for sub_key, sub_value in value.items():\n",
    "                new_key = f'{key}_{sub_key}'\n",
    "                flattened_data[new_key] = sub_value\n",
    "        else:\n",
    "            flattened_data[key] = value\n",
    "    return flattened_data\n",
    "\n",
    "flattened_json_data = flatten_json(json_data)\n",
    "list(flattened_json_data.items())[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m timestamp, timestamp_value \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 9\u001b[0m         row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimestamp\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtimestamp\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m             row \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m: timestamp}\n",
      "Cell \u001b[1;32mIn[4], line 9\u001b[0m, in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m timestamp, timestamp_value \u001b[38;5;129;01min\u001b[39;00m value\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m----> 9\u001b[0m         row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m((row \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows \u001b[38;5;28;01mif\u001b[39;00m row\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[43mtimestamp\u001b[49m), \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m     10\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m row \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     11\u001b[0m             row \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimestamp\u001b[39m\u001b[38;5;124m'\u001b[39m: timestamp}\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Chuyển đổi dữ liệu JSON làm phẳng sang định dạng DataFrame và chuẩn bị cho CSV:\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "rows = []\n",
    "for key, value in flattened_json_data.items():\n",
    "    if isinstance(value, dict):\n",
    "        for timestamp, timestamp_value in value.items():\n",
    "            row = next((row for row in rows if row.get('timestamp') == timestamp), None)\n",
    "            if row is None:\n",
    "                row = {'timestamp': timestamp}\n",
    "                rows.append(row)\n",
    "            row[key] = timestamp_value\n",
    "    else:\n",
    "        for row in rows:\n",
    "            row[key] = value\n",
    "\n",
    "df = pd.DataFrame(rows)\n",
    "df[200:220]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file_path = '../dataset/converted_data.parquet'\n",
    "df.to_parquet(parquet_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>room_temp_Mf-1-1</th>\n",
       "      <th>room_temp_Mf-1-2</th>\n",
       "      <th>room_temp_Mf-1-3</th>\n",
       "      <th>room_temp_Mf-2-1-1</th>\n",
       "      <th>room_temp_Mf-2-1-2</th>\n",
       "      <th>room_temp_Mf-2-1-3</th>\n",
       "      <th>room_temp_Mf-2-1-4</th>\n",
       "      <th>room_temp_Ac-2-1</th>\n",
       "      <th>slab_temp_Plant</th>\n",
       "      <th>...</th>\n",
       "      <th>dew_temp_Mf-2-1</th>\n",
       "      <th>dew_temp_Ac-2-2</th>\n",
       "      <th>dew_temp_Ac-2-3</th>\n",
       "      <th>dew_temp_Ac-2-4</th>\n",
       "      <th>dew_temp_Ac-2-5</th>\n",
       "      <th>fan_stat_Ac-2-1</th>\n",
       "      <th>fan_stat_Ac-2-2</th>\n",
       "      <th>fan_stat_Ac-2-3</th>\n",
       "      <th>fan_stat_Ac-2-4</th>\n",
       "      <th>fan_stat_Ac-2-5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1682899448.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>16.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>17.9</td>\n",
       "      <td>18.2</td>\n",
       "      <td>17.1</td>\n",
       "      <td>16.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1682900648.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>16.2</td>\n",
       "      <td>16.8</td>\n",
       "      <td>17.9</td>\n",
       "      <td>18.3</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>...</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>7.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1682901848.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>16.1</td>\n",
       "      <td>16.7</td>\n",
       "      <td>17.9</td>\n",
       "      <td>18.1</td>\n",
       "      <td>17.0</td>\n",
       "      <td>16.3</td>\n",
       "      <td>15.9</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1682903048.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>16.7</td>\n",
       "      <td>17.8</td>\n",
       "      <td>18.1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>16.2</td>\n",
       "      <td>15.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1682904248.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.1</td>\n",
       "      <td>16.6</td>\n",
       "      <td>17.8</td>\n",
       "      <td>18.1</td>\n",
       "      <td>16.9</td>\n",
       "      <td>16.1</td>\n",
       "      <td>15.8</td>\n",
       "      <td>16.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>7.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp  room_temp_Mf-1-1  room_temp_Mf-1-2  room_temp_Mf-1-3  \\\n",
       "0  1682899448.0              16.1              16.2              16.8   \n",
       "1  1682900648.0              16.1              16.2              16.8   \n",
       "2  1682901848.0              16.1              16.1              16.7   \n",
       "3  1682903048.0              16.0              16.1              16.7   \n",
       "4  1682904248.0              16.0              16.1              16.6   \n",
       "\n",
       "   room_temp_Mf-2-1-1  room_temp_Mf-2-1-2  room_temp_Mf-2-1-3  \\\n",
       "0                17.9                18.2                17.1   \n",
       "1                17.9                18.3                17.0   \n",
       "2                17.9                18.1                17.0   \n",
       "3                17.8                18.1                16.9   \n",
       "4                17.8                18.1                16.9   \n",
       "\n",
       "   room_temp_Mf-2-1-4  room_temp_Ac-2-1  slab_temp_Plant  ...  \\\n",
       "0                16.4              16.0             16.1  ...   \n",
       "1                16.4              16.0             16.1  ...   \n",
       "2                16.3              15.9             16.0  ...   \n",
       "3                16.2              15.8             16.0  ...   \n",
       "4                16.1              15.8             16.0  ...   \n",
       "\n",
       "   dew_temp_Mf-2-1  dew_temp_Ac-2-2  dew_temp_Ac-2-3  dew_temp_Ac-2-4  \\\n",
       "0              7.6              7.6              7.6              7.6   \n",
       "1              7.6              7.6              7.6              7.6   \n",
       "2              7.5              7.5              7.5              7.5   \n",
       "3              7.5              7.5              7.5              7.5   \n",
       "4              7.5              7.5              7.5              7.5   \n",
       "\n",
       "   dew_temp_Ac-2-5  fan_stat_Ac-2-1  fan_stat_Ac-2-2  fan_stat_Ac-2-3  \\\n",
       "0              7.6              0.0              0.0              0.0   \n",
       "1              7.6              0.0              0.0              0.0   \n",
       "2              7.5              0.0              0.0              1.0   \n",
       "3              7.5              0.0              0.0              0.0   \n",
       "4              7.5              0.0              0.0              0.0   \n",
       "\n",
       "   fan_stat_Ac-2-4  fan_stat_Ac-2-5  \n",
       "0              0.0              0.0  \n",
       "1              0.0              0.0  \n",
       "2              1.0              0.0  \n",
       "3              1.0              0.0  \n",
       "4              0.0              0.0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "def process_json(file_path):\n",
    "    # Đọc file JSON\n",
    "    with open(file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    # Danh sách các keys không cần xử lý\n",
    "    ignored_keys = ['schedule', 'thermal_comfort_data', 'issues_count', 'potential_savings']\n",
    "\n",
    "    # Tạo danh sách DataFrame tạm thời\n",
    "    dfs = []\n",
    "\n",
    "    # Duyệt qua từng key trong dữ liệu JSON\n",
    "    for key, value in json_data.items():\n",
    "        if key in ignored_keys or not isinstance(value, dict):\n",
    "            continue\n",
    "\n",
    "        # Tạo DataFrame từ từng phần của JSON\n",
    "        for subkey, subvalue in value.items():\n",
    "            if isinstance(subvalue, dict):\n",
    "                temp_df = pd.DataFrame.from_dict(subvalue, orient='index')\n",
    "                temp_df.index.name = 'timestamp'\n",
    "                temp_df.reset_index(inplace=True)\n",
    "                temp_df.columns = ['timestamp', f'{key}_{subkey}']\n",
    "                dfs.append(temp_df)\n",
    "\n",
    "    # Hợp nhất các DataFrame tạm thời dựa trên cột timestamp\n",
    "    final_df = dfs[0]\n",
    "    for df in dfs[1:]:\n",
    "        final_df = pd.merge(final_df, df, on='timestamp', how='outer')\n",
    "\n",
    "    return final_df\n",
    "\n",
    "# Áp dụng cho file data_prepare_1.json\n",
    "file_path_1 = '../dataset/data_prepare_2.json'\n",
    "df1 = process_json(file_path_1)\n",
    "\n",
    "# Áp dụng cho file data_prepare_8.json\n",
    "file_path_8 = '../dataset/data_prepare_8.json'\n",
    "df8 = process_json(file_path_8)\n",
    "\n",
    "# Hiển thị DataFrame đầu tiên để kiểm tra\n",
    "df1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>room_temp_Ac-2-1</th>\n",
       "      <th>room_temp_Mf-2-1-4</th>\n",
       "      <th>room_temp_Mf-2-1-3</th>\n",
       "      <th>room_temp_Mf-1-2</th>\n",
       "      <th>room_temp_Mf-2-1-2</th>\n",
       "      <th>room_temp_Mf-1-1</th>\n",
       "      <th>room_temp_Mf-2-1-1</th>\n",
       "      <th>room_temp_Mf-1-3</th>\n",
       "      <th>slab_temp_Zone-1</th>\n",
       "      <th>...</th>\n",
       "      <th>dew_temp_Mf-2-1</th>\n",
       "      <th>dew_temp_Ac-2-2</th>\n",
       "      <th>dew_temp_Ac-2-3</th>\n",
       "      <th>dew_temp_Ac-2-4</th>\n",
       "      <th>dew_temp_Ac-2-5</th>\n",
       "      <th>fan_stat_Ac-2-1</th>\n",
       "      <th>fan_stat_Ac-2-2</th>\n",
       "      <th>fan_stat_Ac-2-3</th>\n",
       "      <th>fan_stat_Ac-2-4</th>\n",
       "      <th>fan_stat_Ac-2-5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1701389348.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.5</td>\n",
       "      <td>20.4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>21.5</td>\n",
       "      <td>19.3</td>\n",
       "      <td>21.3</td>\n",
       "      <td>19.8</td>\n",
       "      <td>20.1</td>\n",
       "      <td>...</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1701390548.0</td>\n",
       "      <td>19.8</td>\n",
       "      <td>19.4</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.9</td>\n",
       "      <td>21.5</td>\n",
       "      <td>19.3</td>\n",
       "      <td>21.2</td>\n",
       "      <td>19.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1701391748.0</td>\n",
       "      <td>19.7</td>\n",
       "      <td>19.4</td>\n",
       "      <td>20.4</td>\n",
       "      <td>19.8</td>\n",
       "      <td>21.4</td>\n",
       "      <td>19.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>19.7</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1701392948.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>20.3</td>\n",
       "      <td>19.8</td>\n",
       "      <td>21.4</td>\n",
       "      <td>19.2</td>\n",
       "      <td>21.2</td>\n",
       "      <td>19.6</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1701394148.0</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>20.2</td>\n",
       "      <td>19.7</td>\n",
       "      <td>21.4</td>\n",
       "      <td>19.2</td>\n",
       "      <td>21.1</td>\n",
       "      <td>19.6</td>\n",
       "      <td>19.9</td>\n",
       "      <td>...</td>\n",
       "      <td>12.7</td>\n",
       "      <td>12.7</td>\n",
       "      <td>12.7</td>\n",
       "      <td>12.7</td>\n",
       "      <td>12.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      timestamp  room_temp_Ac-2-1  room_temp_Mf-2-1-4  room_temp_Mf-2-1-3  \\\n",
       "0  1701389348.0              19.8                19.5                20.4   \n",
       "1  1701390548.0              19.8                19.4                20.4   \n",
       "2  1701391748.0              19.7                19.4                20.4   \n",
       "3  1701392948.0              19.6                19.3                20.3   \n",
       "4  1701394148.0              19.6                19.3                20.2   \n",
       "\n",
       "   room_temp_Mf-1-2  room_temp_Mf-2-1-2  room_temp_Mf-1-1  room_temp_Mf-2-1-1  \\\n",
       "0              20.0                21.5              19.3                21.3   \n",
       "1              19.9                21.5              19.3                21.2   \n",
       "2              19.8                21.4              19.2                21.2   \n",
       "3              19.8                21.4              19.2                21.2   \n",
       "4              19.7                21.4              19.2                21.1   \n",
       "\n",
       "   room_temp_Mf-1-3  slab_temp_Zone-1  ...  dew_temp_Mf-2-1  dew_temp_Ac-2-2  \\\n",
       "0              19.8              20.1  ...             12.5             12.5   \n",
       "1              19.7              20.0  ...             12.5             12.5   \n",
       "2              19.7              20.0  ...             12.5             12.5   \n",
       "3              19.6              20.0  ...             12.5             12.5   \n",
       "4              19.6              19.9  ...             12.7             12.7   \n",
       "\n",
       "   dew_temp_Ac-2-3  dew_temp_Ac-2-4  dew_temp_Ac-2-5  fan_stat_Ac-2-1  \\\n",
       "0             12.5             12.5             12.5              0.0   \n",
       "1             12.5             12.5             12.5              0.0   \n",
       "2             12.5             12.5             12.5              0.0   \n",
       "3             12.5             12.5             12.5              0.0   \n",
       "4             12.7             12.7             12.7              0.0   \n",
       "\n",
       "   fan_stat_Ac-2-2  fan_stat_Ac-2-3  fan_stat_Ac-2-4  fan_stat_Ac-2-5  \n",
       "0              0.0              0.0              0.0              0.0  \n",
       "1              0.0              0.0              0.0              0.0  \n",
       "2              0.0              0.0              0.0              0.0  \n",
       "3              0.0              0.0              0.0              0.0  \n",
       "4              0.0              0.0              0.0              0.0  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df8.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file_path = '../dataset/data_prepare_2.parquet'\n",
    "df1.to_parquet(parquet_file_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parquet_file_path = '../dataset/data_prepare_8.parquet'\n",
    "df8.to_parquet(parquet_file_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code merge file JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_dicts_simple(d1, d2):\n",
    "    \"\"\"\n",
    "    Merge two dictionaries without expanding values into lists. Merge only at the first level of each key.\n",
    "    \"\"\"\n",
    "    merged = dict(d1)  # Start with the keys and values of the first dictionary\n",
    "    for key, value in d2.items():\n",
    "        if key in merged and isinstance(value, dict) and isinstance(merged[key], dict):\n",
    "            # Merge dictionaries at the next level\n",
    "            merged[key] = merge_dicts_simple(merged[key], value)\n",
    "        else:\n",
    "            # Overwrite or add the key-value pair\n",
    "            merged[key] = value\n",
    "    return merged\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the additional files\n",
    "file_paths = [\n",
    "    '/mnt/data/data_prepare_2.json',\n",
    "    '/mnt/data/data_prepare_3.json',\n",
    "    '/mnt/data/data_prepare_4.json',\n",
    "    '/mnt/data/data_prepare_5.json',\n",
    "    '/mnt/data/data_prepare_6.json',\n",
    "    '/mnt/data/data_prepare_7.json',\n",
    "    '/mnt/data/data_prepare_8.json'\n",
    "]\n",
    "\n",
    "additional_data = []\n",
    "\n",
    "for path in file_paths:\n",
    "    with open(path, 'r') as file:\n",
    "        additional_data.append(json.load(file))\n",
    "\n",
    "# Merge each of these datasets into the already merged data\n",
    "for data in additional_data:\n",
    "    merged_data_simple = merge_dicts_simple(merged_data_simple, data)\n",
    "\n",
    "# Save the newly merged data to a file\n",
    "final_merged_file_path = '/mnt/data/final_merged_data.json'\n",
    "with open(final_merged_file_path, 'w') as file:\n",
    "    json.dump(merged_data_simple, file, indent=2)\n",
    "\n",
    "final_merged_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizer Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'A small, curious field mouse named Pip wanted to reach the moon. He decided that he could if he found the right help. Pip met Charlie, the rabbit, and Oliver, the deer. Gary, the giraffe, was the tallest animal Pip had ever seen. Otto, the owl, told Pip that the moon is higher than any animal can go.'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "ARTICLE = \"\"\" Once upon a time, there was a small, curious field mouse named Pip. Pip lived in a burrow in a vast, open field. Every night, Pip would scurry out and look up at the twinkling stars and the radiant moon. One day, Pip decided that he was going to find a way to reach the moon. He knew he was small, but he believed he could make it if he found the right help.\n",
    "\n",
    "The next day, Pip came across Charlie, the rabbit, hopping around in the field. Charlie was certainly taller than Pip, so he asked, \"Charlie, you're so tall! How far are you from the moon?\"\n",
    "\n",
    "Charlie laughed, \"Well, Pip, I may be taller than you, but I'm nowhere near tall enough to reach the moon!\"\n",
    "\n",
    "Unfazed, Pip asked Charlie if he could try standing on his head to gauge the height. Chuckling, Charlie bent down, allowing Pip to scamper onto his fluffy ears. Yet, even standing on top of Charlie's head, the moon still seemed so far away.\n",
    "\n",
    "Feeling slightly disappointed but not defeated, Pip thanked Charlie and continued his journey. Next, he met Oliver, the deer. With his large antlers reaching high into the sky, Oliver was certainly taller than Charlie.\n",
    "\n",
    "\"Oliver,\" Pip asked, \"how far is your reach to the moon?\"\n",
    "\n",
    "\"Although my antlers are tall,\" Oliver replied, \"they're not nearly tall enough to touch the moon.\"\n",
    "\n",
    "Eager to try, Pip asked if he could stand on Oliver's antlers. Carefully, Oliver bent down, and Pip, with a bit of effort, climbed atop his antlers. But still, the moon remained out of Pip's reach.\n",
    "\n",
    "Determined, Pip moved on and stumbled upon Gary, the giraffe. With his long neck and high reach, Gary was the tallest animal Pip had ever seen.\n",
    "\n",
    "\"Gary,\" said Pip, panting slightly, \"how far are you from the moon?\"\n",
    "\n",
    "Gary smiled down at Pip, \"I may be the tallest here, Pip, but even I cannot reach the moon.\"\n",
    "\n",
    "Despite this, Pip was eager to try. With Gary's help, Pip climbed up and sat on top of Gary's head. The view was breathtaking, but yet again, the moon was far from his reach.\n",
    "\n",
    "Pip was starting to feel disheartened, but he was not ready to give up. That night, he sat in the field, looking at the moon, wondering how he could get there.\n",
    "\n",
    "Just then, an old wise owl named Otto flew down beside him. \"Pip, why the long face?\" he asked.\n",
    "\n",
    "\"I want to touch the moon,\" Pip confessed. \"But no matter how high I go, it's still so far away.\"\n",
    "\n",
    "Otto chuckled softly. \"Dear Pip, the moon is not something you can reach by height. It's far, far away, higher than any animal can go. But you know, Pip, each night when you look at the moon and marvel at its beauty, you're touching it with your eyes and your heart.\"\n",
    "\n",
    "Pip was silent for a while, looking thoughtfully at the moon. Then, he smiled, realizing that he had been closer to the moon than he thought.\n",
    "\n",
    "From that night forward, Pip knew that even though he couldn't physically touch the moon, he could feel its magic. His dream of reaching the moon had taken him on a great adventure, where he'd met new friends and seen things from heights he'd never imagined.\n",
    "\n",
    "Pip may have been a small field mouse, but his dreams were as big and bright as the moon itself.\n",
    "\n",
    "\"\"\"\n",
    "print(summarizer(ARTICLE, max_length=200, min_length=30, do_sample=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Describe the following data: At time 2023/03/27-21:34:59 the room temperature was 20.0 At time 2023/03/27-21:43:07 the room temperature was 19.9 At time 2023/03/27-21:49:07 the room temperature was 19.9 At time 2023/03/27-22:09:07 the room temperature was 19.9 At time 2023/03/27-22:49:07 the room temperature was 19.8 At time 2023/03/27-23:09:07 the room temperature was 19.8 At time 2023/03/27-23:29:07 the room temperature was 19.8 At time 2023/03/27-23:49:07 the room temperature was 19.8 At time 2023/03/28-00:09:07 the room temperature was 19.8 At time 2023/03/28-00:29:08 the room temperature was 19.7 At time 2023/03/28-00:49:07 the room temperature was 19.7 At time 2023/03/28-01:09:07 the room temperature was 19.6 At time 2023/03/28-01:49:07 the room temperature was 19.6 At time 2023/03/28-02:09:07 the room temperature was 19.6 At time 2023/03/28-02:29:08 the room temperature was 19.5 At time 2023/03/28-02:49:07 the room temperature was 19.5 At time 2023/03/28-03:09:07 the room temperature was 19.5 At time 2023/03/28-03:29:07 the room temperature was 19.5.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, LongT5ForConditionalGeneration\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/long-t5-tglobal-base\")\n",
    "model = LongT5ForConditionalGeneration.from_pretrained(\"google/long-t5-tglobal-base\")\n",
    "\n",
    "# Đoạn văn bản cần tóm tắt\n",
    "text = \"\"\"Describe the following data: At time 2023/03/27-21:34:59 the room temperature was 20.0 At time 2023/03/27-21:43:07 the room temperature was 19.9 At time 2023/03/27-21:49:07 the room temperature was 19.9 At time 2023/03/27-22:09:07 the room temperature was 19.9 At time 2023/03/27-22:29:07 the room temperature was 19.8 At time 2023/03/27-22:49:07 the room temperature was 19.8 At time 2023/03/27-23:09:07 the room temperature was 19.8 At time 2023/03/27-23:29:07 the room temperature was 19.8 At time 2023/03/27-23:49:07 the room temperature was 19.8 At time 2023/03/28-00:09:07 the room temperature was 19.8 At time 2023/03/28-00:29:08 the room temperature was 19.7 At time 2023/03/28-00:49:07 the room temperature was 19.7 At time 2023/03/28-01:09:07 the room temperature was 19.6 At time 2023/03/28-01:29:07 the room temperature was 19.6 At time 2023/03/28-01:49:07 the room temperature was 19.6 At time 2023/03/28-02:09:07 the room temperature was 19.6 At time 2023/03/28-02:29:08 the room temperature was 19.5 At time 2023/03/28-02:49:07 the room temperature was 19.5 At time 2023/03/28-03:09:07 the room temperature was 19.5 At time 2023/03/28-03:29:07 the room temperature was 19.5.\n",
    "\"\"\"\n",
    "\n",
    "# Mã hóa đoạn văn bản\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "\n",
    "# Tạo ra tóm tắt\n",
    "summary_ids = model.generate(inputs.input_ids, max_length=350, min_length=100, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "# Giải mã kết quả để nhận được văn bản tóm tắt\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At time 2023/03/27-21:34:59 the room temperature was 20.0. At time 2024/02/08/09/10/11/12/13/14/15/16/17/18/19/20/21/22/23/24/25/26/27/28/29/30/31/2/3/4/5/6/7/8/9/10, 11/12, 12/13, 13/14, 14/15, 15/16, 16/17, 17/18, 18/19, 19/20, 19.3, 19, 20, 21/22, 22/23, 23/24, 24/25, 25/26, 26/27, 27/28, 28/29, 29/30, 30/31, 31/32, 32/33, 33/34, 34/36, 36/37, 37/38, 38/39, 39/40, 40/41, 41/42, 42/43, 43/44, 44/45, 45/46, 46/47, 47/48, 48/49,\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Khởi tạo pipeline tóm tắt với mô hình BART\n",
    "# Test các model: FLAN-T5, CNN_Falcon_7b\n",
    "summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "# Đoạn văn bản cần tóm tắt\n",
    "article = \"\"\" Describe the following data: At time 2023/03/27-21:34:59 the room temperature was 20.0 At time 2023/03/27-21:43:07 the room temperature was 19.9 At time 2023/03/27-21:49:07 the room temperature was 19.9 At time 2023/03/27-22:09:07 the room temperature was 19.9 At time 2023/03/27-22:29:07 the room temperature was 19.8 At time 2023/03/27-22:49:07 the room temperature was 19.8 At time 2023/03/27-23:09:07 the room temperature was 19.8 At time 2023/03/27-23:29:07 the room temperature was 19.8 At time 2023/03/27-23:49:07 the room temperature was 19.8 At time 2023/03/28-00:09:07 the room temperature was 19.8 At time 2023/03/28-00:29:08 the room temperature was 19.7 At time 2023/03/28-00:49:07 the room temperature was 19.7 At time 2023/03/28-01:09:07 the room temperature was 19.6 At time 2023/03/28-01:29:07 the room temperature was 19.6 At time 2023/03/28-01:49:07 the room temperature was 19.6 At time 2023/03/28-02:09:07 the room temperature was 19.6 At time 2023/03/28-02:29:08 the room temperature was 19.5 At time 2023/03/28-02:49:07 the room temperature was 19.5 At time 2023/03/28-03:09:07 the room temperature was 19.5 At time 2023/03/28-03:29:07 the room temperature was 19.5.\n",
    "\"\"\"\n",
    "\n",
    "# Tóm tắt văn bản\n",
    "summary = summarizer(article, max_length=250, min_length=100, do_sample=False)\n",
    "\n",
    "# In ra tóm tắt\n",
    "print(summary[0]['summary_text'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from orion import Orion\n",
    "from transformers import GPT3Tokenizer, GPT3Model\n",
    "\n",
    "# Bước 1: Tải dữ liệu\n",
    "data = pd.read_csv(\"data.csv\")\n",
    "\n",
    "# Bước 2: Phát hiện bất thường\n",
    "# Lưu ý: Orion cần được cấu hình chính xác theo nhu cầu của dữ liệu\n",
    "orion = Orion(pipeline='lstm_dynamic_threshold')\n",
    "anomalies = orion.fit_detect(data)\n",
    "\n",
    "# Bước 3: Chuẩn bị dữ liệu cho mô hình GPT-3\n",
    "# Chuyển DataFrame thành numpy array\n",
    "data_np = data.to_numpy()\n",
    "\n",
    "# Tokenize dữ liệu (đối với mô hình LLM như GPT-3)\n",
    "tokenizer = GPT3Tokenizer.from_pretrained(\"gpt3\")\n",
    "input_ids = tokenizer(data_np.tolist(), return_tensors='pt', padding=True, truncation=True)['input_ids']\n",
    "\n",
    "# Bước 4: Sử dụng mô hình GPT-3 để tạo báo cáo\n",
    "# Lưu ý: GPT-3 thường được sử dụng qua API, ở đây chỉ là ví dụ về cách load mô hình\n",
    "model = GPT3Model.from_pretrained(\"gpt3\")\n",
    "outputs = model.generate(input_ids)\n",
    "report = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The room temperature was 20.0 degrees Fahrenheit. The time stamps were 20:34:59 and 21:34:59 respectively. The time stamps were 20:43:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:49:07 respectively. The time stamps were 20:43:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43:07 respectively. The time stamps were 20:49:07 and 21:43']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "\n",
    "inputs = tokenizer(\"\"\"Describe the following data of room temperature with a summary of the trends, patterns, and any notable observations: Describe the following data: Timestamp|2023/03/27-21:34:59 room_temperature|20.0 Timestamp|2023/03/27-21:43:07 room_temperature|19.9 Timestamp|2023/03/27-21:49:07 room_temperature|19.9 Timestamp|2023/03/27-22:09:07 room_temperature|19.9 Timestamp|2023/03/27-22:29:07 room_temperature|19.8 Timestamp|2023/03/27-22:49:07 room_temperature|19.8 Timestamp|2023/03/27-23:09:07 room_temperature|19.8 Timestamp|2023/03/27-23:29:07 room_temperature|19.8 Timestamp|2023/03/27-23:49:07 room_temperature|19.8 Timestamp|2023/03/28-00:09:07 room_temperature|19.8 Timestamp|2023/03/28-00:29:08 room_temperature|19.7 Timestamp|2023/03/28-00:49:07 room_temperature|19.7 Timestamp|2023/03/28-01:09:07 room_temperature|19.6 Timestamp|2023/03/28-01:29:07 room_temperature|19.6 Timestamp|2023/03/28-01:49:07 room_temperature|19.6 Timestamp|2023/03/28-02:09:07 room_temperature|19.6 Timestamp|2023/03/28-02:29:08 room_temperature|19.5 Timestamp|2023/03/28-02:49:07 room_temperature|19.5 Timestamp|2023/03/28-03:09:07 room_temperature|19.5 Timestamp|2023/03/28-03:29:07 room_temperature|19.5.\n",
    "\"\"\", return_tensors=\"pt\")\n",
    "\n",
    "# Sinh đầu ra với độ dài tối đa được chỉ định\n",
    "max_length = 512  # Ví dụ, tăng giá trị này để có đầu ra dài hơn\n",
    "min_length = 50   # Đặt một giới hạn dài tối thiểu\n",
    "length_penalty = 2.0 # Tăng giá trị này để khuyến khích đầu ra dài hơn\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=max_length, min_length=min_length, length_penalty=length_penalty)\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['At time 2023/03/28-03:29:07 the room temperature was 19.5, at time 2023/03/28-00:09:07 the room temperature was 19.8, at time 2023/03/28-00:29:08 the room temperature was 19.7, at time 2023/03/28-00:49:07 the room temperature was 19.7, at time 2023/03/28-01:09:07 the room temperature was 19.6, at time 2023/03/28-01:29:07 the room temperature was 19.6, at time 2023/03/28-01:49:07 the room temperature was 19.6, at time 2023/03/28-02:09:07 the room temperature was 19.6, at time 2023/03/28-02:29:08 the room temperature was 19.6, at time 2023/03/28-03:09:07 the room temperature was 19.5, at time 2023/03/28-03:29:07 the room temperature was 19.5,']\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-large\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-large\")\n",
    "\n",
    "input_text = \"\"\" \n",
    "Describe the following data: At time 2023/03/27-21:34:59 the room temperature was 20.0 At time 2023/03/27-21:43:07 the room temperature was 19.9 At time 2023/03/27-21:49:07 the room temperature was 19.9 At time 2023/03/27-22:09:07 the room temperature was 19.9 At time 2023/03/27-22:29:07 the room temperature was 19.8 At time 2023/03/27-22:49:07 the room temperature was 19.8 At time 2023/03/27-23:09:07 the room temperature was 19.8 At time 2023/03/27-23:29:07 the room temperature was 19.8 At time 2023/03/27-23:49:07 the room temperature was 19.8 At time 2023/03/28-00:09:07 the room temperature was 19.8 At time 2023/03/28-00:29:08 the room temperature was 19.7 At time 2023/03/28-00:49:07 the room temperature was 19.7 At time 2023/03/28-01:09:07 the room temperature was 19.6 At time 2023/03/28-01:29:07 the room temperature was 19.6 At time 2023/03/28-01:49:07 the room temperature was 19.6 At time 2023/03/28-02:09:07 the room temperature was 19.6 At time 2023/03/28-02:29:08 the room temperature was 19.5 At time 2023/03/28-02:49:07 the room temperature was 19.5 At time 2023/03/28-03:09:07 the room temperature was 19.5 At time 2023/03/28-03:29:07 the room temperature was 19.5.\n",
    "\"\"\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# Sinh đầu ra với độ dài tối đa được chỉ định\n",
    "max_length = 512  # Ví dụ, tăng giá trị này để có đầu ra dài hơn\n",
    "min_length = 100   # Đặt một giới hạn dài tối thiểu\n",
    "length_penalty = 4.0 # Tăng giá trị này để khuyến khích đầu ra dài hơn\n",
    "\n",
    "outputs = model.generate(**inputs, max_length=max_length, min_length=min_length)\n",
    "print(tokenizer.batch_decode(outputs, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\phamh\\.conda\\envs\\chart2text\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Loading checkpoint shards:   0%|          | 0/2 [01:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 5\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m# Load the tokenizer and model\u001b[39;00m\n\u001b[0;32m      4\u001b[0m tokenizer \u001b[38;5;241m=\u001b[39m AutoTokenizer\u001b[38;5;241m.\u001b[39mfrom_pretrained(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmistralai/Mistral-7B-Instruct-v0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForCausalLM\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmistralai/Mistral-7B-Instruct-v0.1\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# Prepare your input text\u001b[39;00m\n\u001b[0;32m      8\u001b[0m input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124mGenerate a report analyzing the following time-series data. Each entry consists of a timestamp and a corresponding measurement value. \u001b[39m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;124mThe data is as follows: At timestamp 1690910402.0, the value was 20.5. At timestamp 1690911602.0, the value was 20.0. At timestamp 1690912802.0, the value was 20.0. At timestamp 1690914002.0, the value was 20.0. At timestamp 1690915203.0, the value was 19.5. At timestamp 1690916403.0, the value was 19.5. At timestamp 1690917602.0, the value was 19.5. At timestamp 1690918802.0, the value was 19.0. At timestamp 1690920002.0, the value was 19.0. At timestamp 1690921202.0, the value was 19.0. At timestamp 1690922402.0, the value was 19.0. At timestamp 1690923602.0, the value was 19.0. At timestamp 1690924802.0, the value was 18.5. At timestamp 1690926002.0, the value was 18.5. At timestamp 1690927202.0, the value was 18.0. At timestamp 1690928402.0, the value was 18.0. At timestamp 1690929602.0, the value was 18.0. At timestamp 1690930802.0, the value was 18.0. At timestamp 1690932002.0, the value was 18.0. At timestamp 1690933202.0, the value was 17.5. At timestamp 1690934402.0, the value was 17.5. At timestamp 1690935602.0, the value was 17.5. At timestamp 1690936802.0, the value was 17.5. At timestamp 1690938002.0, the value was 17.0. At timestamp 1690939203.0, the value was 17.0. At timestamp 1690940402.0, the value was 17.0. At timestamp 1690941602.0, the value was 17.0. \u001b[39m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;124mConclude the report with a summary of the trends, patterns, and any notable observations.\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\phamh\\.conda\\envs\\chart2text\\lib\\site-packages\\transformers\\models\\auto\\auto_factory.py:566\u001b[0m, in \u001b[0;36m_BaseAutoModelClass.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(config) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[0;32m    565\u001b[0m     model_class \u001b[38;5;241m=\u001b[39m _get_model_class(config, \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping)\n\u001b[1;32m--> 566\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m model_class\u001b[38;5;241m.\u001b[39mfrom_pretrained(\n\u001b[0;32m    567\u001b[0m         pretrained_model_name_or_path, \u001b[38;5;241m*\u001b[39mmodel_args, config\u001b[38;5;241m=\u001b[39mconfig, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mhub_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m    568\u001b[0m     )\n\u001b[0;32m    569\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    570\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnrecognized configuration class \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for this kind of AutoModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    571\u001b[0m     \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel type should be one of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(c\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mfor\u001b[39;00m\u001b[38;5;250m \u001b[39mc\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01min\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m_model_mapping\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    572\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\phamh\\.conda\\envs\\chart2text\\lib\\site-packages\\transformers\\modeling_utils.py:3694\u001b[0m, in \u001b[0;36mPreTrainedModel.from_pretrained\u001b[1;34m(cls, pretrained_model_name_or_path, config, cache_dir, ignore_mismatched_sizes, force_download, local_files_only, token, revision, use_safetensors, *model_args, **kwargs)\u001b[0m\n\u001b[0;32m   3685\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_orig \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   3686\u001b[0m         torch\u001b[38;5;241m.\u001b[39mset_default_dtype(dtype_orig)\n\u001b[0;32m   3687\u001b[0m     (\n\u001b[0;32m   3688\u001b[0m         model,\n\u001b[0;32m   3689\u001b[0m         missing_keys,\n\u001b[0;32m   3690\u001b[0m         unexpected_keys,\n\u001b[0;32m   3691\u001b[0m         mismatched_keys,\n\u001b[0;32m   3692\u001b[0m         offload_index,\n\u001b[0;32m   3693\u001b[0m         error_msgs,\n\u001b[1;32m-> 3694\u001b[0m     ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_pretrained_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   3695\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloaded_state_dict_keys\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# XXX: rename?\u001b[39;49;00m\n\u001b[0;32m   3698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresolved_archive_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpretrained_model_name_or_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_mismatched_sizes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3701\u001b[0m \u001b[43m        \u001b[49m\u001b[43msharded_metadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msharded_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3702\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_fast_init\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_fast_init\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3703\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlow_cpu_mem_usage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3704\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice_map\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3705\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_folder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_folder\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3706\u001b[0m \u001b[43m        \u001b[49m\u001b[43moffload_state_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moffload_state_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3707\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtorch_dtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3708\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_quantized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquantization_method\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mQuantizationMethod\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBITS_AND_BYTES\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3709\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeep_in_fp32_modules\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   3710\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3712\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_4bit \u001b[38;5;241m=\u001b[39m load_in_4bit\n\u001b[0;32m   3713\u001b[0m model\u001b[38;5;241m.\u001b[39mis_loaded_in_8bit \u001b[38;5;241m=\u001b[39m load_in_8bit\n",
      "File \u001b[1;32mc:\\Users\\phamh\\.conda\\envs\\chart2text\\lib\\site-packages\\transformers\\modeling_utils.py:4122\u001b[0m, in \u001b[0;36mPreTrainedModel._load_pretrained_model\u001b[1;34m(cls, model, state_dict, loaded_keys, resolved_archive_file, pretrained_model_name_or_path, ignore_mismatched_sizes, sharded_metadata, _fast_init, low_cpu_mem_usage, device_map, offload_folder, offload_state_dict, dtype, is_quantized, keep_in_fp32_modules)\u001b[0m\n\u001b[0;32m   4120\u001b[0m         error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_error_msgs\n\u001b[0;32m   4121\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 4122\u001b[0m     error_msgs \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43m_load_state_dict_into_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_prefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4124\u001b[0m \u001b[38;5;66;03m# force memory release\u001b[39;00m\n\u001b[0;32m   4125\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "File \u001b[1;32mc:\\Users\\phamh\\.conda\\envs\\chart2text\\lib\\site-packages\\transformers\\modeling_utils.py:606\u001b[0m, in \u001b[0;36m_load_state_dict_into_model\u001b[1;34m(model_to_load, state_dict, start_prefix)\u001b[0m\n\u001b[0;32m    603\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    604\u001b[0m             load(child, state_dict, prefix \u001b[38;5;241m+\u001b[39m name \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 606\u001b[0m \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_to_load\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstart_prefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    607\u001b[0m \u001b[38;5;66;03m# Delete `state_dict` so it could be collected by GC earlier. Note that `state_dict` is a copy of the argument, so\u001b[39;00m\n\u001b[0;32m    608\u001b[0m \u001b[38;5;66;03m# it's safe to delete it.\u001b[39;00m\n\u001b[0;32m    609\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m state_dict\n",
      "File \u001b[1;32mc:\\Users\\phamh\\.conda\\envs\\chart2text\\lib\\site-packages\\transformers\\modeling_utils.py:604\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[1;34m(module, state_dict, prefix)\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 604\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\phamh\\.conda\\envs\\chart2text\\lib\\site-packages\\transformers\\modeling_utils.py:604\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[1;34m(module, state_dict, prefix)\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 604\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "    \u001b[1;31m[... skipping similar frames: _load_state_dict_into_model.<locals>.load at line 604 (2 times)]\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\phamh\\.conda\\envs\\chart2text\\lib\\site-packages\\transformers\\modeling_utils.py:604\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[1;34m(module, state_dict, prefix)\u001b[0m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 604\u001b[0m         \u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchild\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\phamh\\.conda\\envs\\chart2text\\lib\\site-packages\\transformers\\modeling_utils.py:600\u001b[0m, in \u001b[0;36m_load_state_dict_into_model.<locals>.load\u001b[1;34m(module, state_dict, prefix)\u001b[0m\n\u001b[0;32m    598\u001b[0m                     module\u001b[38;5;241m.\u001b[39m_load_from_state_dict(\u001b[38;5;241m*\u001b[39margs)\n\u001b[0;32m    599\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 600\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_from_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    602\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, child \u001b[38;5;129;01min\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_modules\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m    603\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m child \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\phamh\\.conda\\envs\\chart2text\\lib\\site-packages\\torch\\nn\\modules\\module.py:2040\u001b[0m, in \u001b[0;36mModule._load_from_state_dict\u001b[1;34m(self, state_dict, prefix, local_metadata, strict, missing_keys, unexpected_keys, error_msgs)\u001b[0m\n\u001b[0;32m   2038\u001b[0m                 \u001b[38;5;28msetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, name, input_param)\n\u001b[0;32m   2039\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2040\u001b[0m             \u001b[43mparam\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy_\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_param\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2041\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m   2042\u001b[0m     error_msgs\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWhile copying the parameter named \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2043\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhose dimensions in the model are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m and \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2044\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwhose dimensions in the checkpoint are \u001b[39m\u001b[38;5;132;01m{\u001b[39;00minput_param\u001b[38;5;241m.\u001b[39msize()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2045\u001b[0m                       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124man exception occurred : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;241m.\u001b[39margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   2046\u001b[0m                       )\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "# Load the tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mistral-7B-Instruct-v0.1\")\n",
    "\n",
    "# Prepare your input text\n",
    "input_text = \"\"\"\n",
    "Generate a report analyzing the following time-series data. Each entry consists of a timestamp and a corresponding measurement value. \n",
    "The data is as follows: At timestamp 1690910402.0, the value was 20.5. At timestamp 1690911602.0, the value was 20.0. At timestamp 1690912802.0, the value was 20.0. At timestamp 1690914002.0, the value was 20.0. At timestamp 1690915203.0, the value was 19.5. At timestamp 1690916403.0, the value was 19.5. At timestamp 1690917602.0, the value was 19.5. At timestamp 1690918802.0, the value was 19.0. At timestamp 1690920002.0, the value was 19.0. At timestamp 1690921202.0, the value was 19.0. At timestamp 1690922402.0, the value was 19.0. At timestamp 1690923602.0, the value was 19.0. At timestamp 1690924802.0, the value was 18.5. At timestamp 1690926002.0, the value was 18.5. At timestamp 1690927202.0, the value was 18.0. At timestamp 1690928402.0, the value was 18.0. At timestamp 1690929602.0, the value was 18.0. At timestamp 1690930802.0, the value was 18.0. At timestamp 1690932002.0, the value was 18.0. At timestamp 1690933202.0, the value was 17.5. At timestamp 1690934402.0, the value was 17.5. At timestamp 1690935602.0, the value was 17.5. At timestamp 1690936802.0, the value was 17.5. At timestamp 1690938002.0, the value was 17.0. At timestamp 1690939203.0, the value was 17.0. At timestamp 1690940402.0, the value was 17.0. At timestamp 1690941602.0, the value was 17.0. \n",
    "Conclude the report with a summary of the trends, patterns, and any notable observations.\n",
    "\"\"\"\n",
    "\n",
    "# Encode the input text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors='pt')\n",
    "\n",
    "# Generate a response\n",
    "outputs = model.generate(input_ids)\n",
    "\n",
    "# Decode and print the response\n",
    "print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Your max_length is set to 512, but your input_length is only 354. Since this is a summarization task, where outputs shorter than the input are typically wanted, you might consider decreasing max_length manually, e.g. summarizer('...', max_length=177)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'summary_text': 'At time 2023/03/28-02:09:07 the room temperature was 19.2 . At time 1923/03/27-03:29:07 at time 192/03/28-04:09 . The room temperature is 19.2 at time 2022/03/28-01:29.08 the room was 19.2. At time . 2023/28-03 :09,07 the . room temperature had 19.2 by 2023 . By 2023/05/28-05:29 .'}]\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "summarizer = pipeline(\"summarization\", model=\"Falconsai/text_summarization\")\n",
    "\n",
    "ARTICLE = \"\"\" \n",
    "At time 2023/03/27-21:34:59 the room temperature was 19.4. At time 2023/03/27-21:43:07 the room temperature was 19.4. At time 2023/03/27-21:49:07 the room temperature was 19.4. At time 2023/03/27-22:09:07 the room temperature was 19.3. At time 2023/03/27-22:29:07 the room temperature was 19.3. At time 2023/03/27-22:49:07 the room temperature was 19.3. At time 2023/03/27-23:09:07 the room temperature was 19.4. At time 2023/03/27-23:29:07 the room temperature was 19.4. At time 2023/03/27-23:49:07 the room temperature was 19.4. At time 2023/03/28-00:09:07 the room temperature was 19.3. At time 2023/03/28-00:29:08 the room temperature was 19.3. At time 2023/03/28-00:49:07 the room temperature was 19.3. At time 2023/03/28-01:09:07 the room temperature was 19.3. At time 2023/03/28-01:29:07 the room temperature was 19.3. At time 2023/03/28-01:49:07 the room temperature was 19.2. At time 2023/03/28-02:09:07 the room temperature was 19.2. At time 2023/03/28-02:29:08 the room temperature was 19.2. At time 2023/03/28-02:49:07 the room temperature was 19.2. At time 2023/03/28-03:09:07 the room temperature was 19.2. At time 2023/03/28-03:29:07 the room temperature was 19.2.\n",
    "\"\"\"\n",
    "print(summarizer(ARTICLE, max_length=512, min_length=30, do_sample=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At time 2023/03/27-21:34:59 the room temperature was 20.0 At time 20th/March/27 -21:43:07 the room temp was 19.9 At time 2017-03-27-22:09:09The room temperature is 19.5% of the world’s population, according to the World Health Organization (WHO) 2017 World Population Survey (WPS) 2017-02-27The world population is expected to grow by 1.4 billion people over the next 10 years, with the majority of the population living in urbanised areas.The U.S. is projected to grow at a rate of 1.6% per year for the next decade, with urbanization accounting for more than half of the global population by 2050.According to the WHO, the world population will grow by 2.5 billion people by 2050, and urbanization will be the largest contributor to global population growth.The WPS estimates that the average annual global temperature will increase to 20.5 degrees Celsius by 2023, and the average global greenhouse gas emissions (GHG) will fall to 0.8g per year.The global GHG emissions are projected to fall to 1.7g per person per year by 2027, and are expected to reach a global average of 0.4g by 2028.The average global carbon dioxide emissions per person will fall by 0.6g by 2030.The world's population is predicted to grow 1.5 percent per year, with most urbanised cities housing more than one billion people.The World Bank predicts that the global average global temperature is likely to increase to 19.6 degrees Celsius in 2023.The United Nations predicts that urbanisation will grow to 2.7 million people by 2030, and that urbanization could reach as high as 2.9m by 2040.The Global Burden of Carbon (GBC) is estimated to grow to 3.5 gigatons by 2035.The GBC predicts that global GDP will grow at an annual rate of 2.4% by 2037, and global greenhouse-gas emissions (GHA) will reach 0.5g/tonne by 2038.The UK's Global Bodies of Human Capital (GBHC) are estimated to have a negative impact on global GDP growth by 2033.The GBHC predicts that total global greenhouse emissions will increase by 2Gigatons per person by\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"allenai/PRIMERA\")\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\"allenai/PRIMERA\")\n",
    "\n",
    "# Đoạn văn bản cần tóm tắt\n",
    "text = \"\"\"At time 2023/03/27-21:34:59 the room temperature was 20.0 At time 2023/03/27-21:43:07 the room temperature was 19.9 At time 2023/03/27-21:49:07 the room temperature was 19.9 At time 2023/03/27-22:09:07 the room temperature was 19.9 At time 2023/03/27-22:29:07 the room temperature was 19.8 At time 2023/03/27-22:49:07 the room temperature was 19.8 At time 2023/03/27-23:09:07 the room temperature was 19.8 At time 2023/03/27-23:29:07 the room temperature was 19.8 At time 2023/03/27-23:49:07 the room temperature was 19.8 At time 2023/03/28-00:09:07 the room temperature was 19.8 At time 2023/03/28-00:29:08 the room temperature was 19.7 At time 2023/03/28-00:49:07 the room temperature was 19.7 At time 2023/03/28-01:09:07 the room temperature was 19.6 At time 2023/03/28-01:29:07 the room temperature was 19.6 At time 2023/03/28-01:49:07 the room temperature was 19.6 At time 2023/03/28-02:09:07 the room temperature was 19.6 At time 2023/03/28-02:29:08 the room temperature was 19.5 At time 2023/03/28-02:49:07 the room temperature was 19.5 At time 2023/03/28-03:09:07 the room temperature was 19.5 At time 2023/03/28-03:29:07 the room temperature was 19.5.\n",
    "\"\"\"\n",
    "\n",
    "# Mã hóa đoạn văn bản\n",
    "inputs = tokenizer(text, return_tensors=\"pt\", max_length=1024, truncation=True)\n",
    "\n",
    "# Tạo ra tóm tắt\n",
    "summary_ids = model.generate(inputs.input_ids, max_length=500, min_length=100, length_penalty=2.0, num_beams=4, early_stopping=True)\n",
    "\n",
    "# Giải mã kết quả để nhận được văn bản tóm tắt\n",
    "summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Room Temperature range from 20.0 °C to 20.9 °C Timestamp from 2023/03/27-21:34:59 Room temperature range from 19.9 to 19.5 °C timestamped from 20 to 21:43:07 Room Temperature range between 19.8 °C and 19.6 °C TIMESTAMP from 20 23 March to 21 March Room Temperature ranges from 19°C to 19°F Timestamped between 20.8°C and 20.6°C']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import MvpTokenizer, MvpForConditionalGeneration\n",
    "\n",
    "tokenizer = MvpTokenizer.from_pretrained(\"RUCAIBox/mvp\")\n",
    "model = MvpForConditionalGeneration.from_pretrained(\"RUCAIBox/mtl-data-to-text\")\n",
    "\n",
    "inputs = tokenizer(\n",
    "    \"\"\" Describe the following data: Timestamp|2023/03/27-21:34:59 room_temperature|20.0 Timestamp|2023/03/27-21:43:07 room_temperature|19.9 Timestamp|2023/03/27-21:49:07 room_temperature|19.9 Timestamp|2023/03/27-22:09:07 room_temperature|19.9 Timestamp|2023/03/27-22:29:07 room_temperature|19.8 Timestamp|2023/03/27-22:49:07 room_temperature|19.8 Timestamp|2023/03/27-23:09:07 room_temperature|19.8 Timestamp|2023/03/27-23:29:07 room_temperature|19.8 Timestamp|2023/03/27-23:49:07 room_temperature|19.8 Timestamp|2023/03/28-00:09:07 room_temperature|19.8 Timestamp|2023/03/28-00:29:08 room_temperature|19.7 Timestamp|2023/03/28-00:49:07 room_temperature|19.7 Timestamp|2023/03/28-01:09:07 room_temperature|19.6 Timestamp|2023/03/28-01:29:07 room_temperature|19.6 Timestamp|2023/03/28-01:49:07 room_temperature|19.6 Timestamp|2023/03/28-02:09:07 room_temperature|19.6 Timestamp|2023/03/28-02:29:08 room_temperature|19.5 Timestamp|2023/03/28-02:49:07 room_temperature|19.5 Timestamp|2023/03/28-03:09:07 room_temperature|19.5 Timestamp|2023/03/28-03:29:07 room_temperature|19.5\"\"\",\n",
    "    return_tensors=\"pt\",\n",
    ")\n",
    "generated_ids = model.generate(**inputs, max_length=512, min_length=100)\n",
    "tokenizer.batch_decode(generated_ids, skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp|2023/03/27-21:34:59|x|line_chart room_temperature_Ac-2-1|20.0|y|line_chart Timestamp|2023/03/27-21:43:07|x|line_chart room_temperature_Ac-2-1|19.9|y|line_chart Timestamp|2023/03/27-21:49:07|x|line_chart room_temperature_Ac-2-1|19.9|y|line_chart Timestamp|2023/03/27-22:09:07|x|line_chart room_temperature_Ac-2-1|19.9|y|line_chart Timestamp|2023/03/27-22:29:07|x|line_chart room_temperature_Ac-2-1|19.8|y|line_chart Timestamp|2023/03/27-22:49:07|x|line_chart room_temperature_Ac-2-1|19.8|y|l\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Bước 1: Đọc dữ liệu từ file Excel\n",
    "file_path = '../dataset/Book1.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "df = df.fillna(-1)\n",
    "\n",
    "# Bước 2: Chuyển đổi timestamp thành dạng ngày giờ có thể đọc được\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s').dt.strftime('%Y/%m/%d-%H:%M:%S')\n",
    "\n",
    "# Bước 3: Định dạng mỗi dòng dữ liệu\n",
    "formatted_data_new = df.apply(lambda x: f\"Timestamp|{x['timestamp']}|x|line_chart room_temperature_Ac-2-1|{x['room_temp_Ac-2-1']}|y|line_chart\", axis=1)\n",
    "\n",
    "# Bước 4: Gộp tất cả dữ liệu thành một dòng duy nhất, cách nhau bởi dấu cách\n",
    "single_line_format = ' '.join(formatted_data_new)\n",
    "\n",
    "# In ra kết quả (chỉ một phần để kiểm tra)\n",
    "print(single_line_format[:500])  # In ra 500 ký tự đầu tiên để kiểm tra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../dataset/formatted_room_temperature_data.txt'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File path for the output text file\n",
    "output_file_path = '../dataset/formatted_room_temperature_data.txt'\n",
    "\n",
    "# Writing the single line formatted data to a text file\n",
    "with open(output_file_path, 'w') as file:\n",
    "    file.write(single_line_format)\n",
    "\n",
    "output_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At time 2023/03/27-21:34:59 the room temperature was 20.0 At time 2023/03/27-21:43:07 the room temperature was 19.9 At time 2023/03/27-21:49:07 the room temperature was 19.9 At time 2023/03/27-22:09:07 the room temperature was 19.9 At time 2023/03/27-22:29:07 the room temperature was 19.8 At time 2023/03/27-22:49:07 the room temperature was 19.8 At time 2023/03/27-23:09:07 the room temperature was 19.8 At time 2023/03/27-23:29:07 the room temperature was 19.8 At time 2023/03/27-23:49:07 the room\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Bước 1: Đọc dữ liệu từ file Excel\n",
    "file_path = '../dataset/Book2.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "df = df.fillna(-1)\n",
    "\n",
    "# Bước 2: Chuyển đổi timestamp thành dạng ngày giờ có thể đọc được\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s').dt.strftime('%Y/%m/%d-%H:%M:%S')\n",
    "\n",
    "# Bước 3: Định dạng mỗi dòng dữ liệu\n",
    "formatted_data_new = df.apply(lambda x: f\"At time {x['timestamp']} the room temperature was {x['room_temp_Ac-2-1']}\", axis=1)\n",
    "\n",
    "# Bước 4: Gộp tất cả dữ liệu thành một dòng duy nhất, cách nhau bởi dấu cách\n",
    "single_line_format = ' '.join(formatted_data_new)\n",
    "\n",
    "# In ra kết quả (chỉ một phần để kiểm tra)\n",
    "print(single_line_format[:500])  # In ra 500 ký tự đầu tiên để kiểm tra\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../dataset/formatted_data.txt'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# File path for the output text file\n",
    "output_file_path = '../dataset/formatted_data.txt'\n",
    "\n",
    "# Writing the single line formatted data to a text file\n",
    "with open(output_file_path, 'w') as file:\n",
    "    file.write(single_line_format)\n",
    "\n",
    "output_file_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code chuyển đổi file sang CSV cho Bart và T5 Train, Validation, Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Global spending on motorsports sponsorships 20...</td>\n",
       "      <td>This statistic shows the worldwide spending fo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fixed broadband internet subscription rate 201...</td>\n",
       "      <td>This statistic illustrates the fixed broadband...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Audi - operating profit 2002 to 2018: Year|201...</td>\n",
       "      <td>This statistic represents Audi 's operating pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Amazon Web Services : TTM revenue 2014 to 2019...</td>\n",
       "      <td>The statistic illustrates the TTM revenue of A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Food retail sales growth in the United Kingdom...</td>\n",
       "      <td>In 2016 , data forecast expected retail sales ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  \\\n",
       "0  Global spending on motorsports sponsorships 20...   \n",
       "1  Fixed broadband internet subscription rate 201...   \n",
       "2  Audi - operating profit 2002 to 2018: Year|201...   \n",
       "3  Amazon Web Services : TTM revenue 2014 to 2019...   \n",
       "4  Food retail sales growth in the United Kingdom...   \n",
       "\n",
       "                                             summary  \n",
       "0  This statistic shows the worldwide spending fo...  \n",
       "1  This statistic illustrates the fixed broadband...  \n",
       "2  This statistic represents Audi 's operating pr...  \n",
       "3  The statistic illustrates the TTM revenue of A...  \n",
       "4  In 2016 , data forecast expected retail sales ...  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "title_file = '../Chart2Text/data/train/trainTitle.txt'\n",
    "data_file = '../Chart2Text/data/train/trainData.txt'\n",
    "summary_file = '../Chart2Text/data/train/trainOriginalSummary.txt'\n",
    "\n",
    "# Load the first 50 lines of each file\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    lines = [line.strip() for line in lines]\n",
    "    return pd.DataFrame(lines, columns=['data'])\n",
    "\n",
    "# Đọc dữ liệu từ các file\n",
    "title_df = read_txt_file(title_file)\n",
    "data_df = read_txt_file(data_file)\n",
    "summary_df = read_txt_file(summary_file)\n",
    "\n",
    "# Ghép cột title và data\n",
    "combined_data = title_df['data'] + \": \" + data_df['data']\n",
    "\n",
    "# Tạo DataFrame mới từ cột data ghép và summary\n",
    "combined_df = pd.DataFrame({\n",
    "    'data': combined_data,\n",
    "    'summary': summary_df['data']\n",
    "})\n",
    "\n",
    "\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Light truck sales in the United States 1980 to...</td>\n",
       "      <td>Light truck retail sales in the United States ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Global TV audience/viewership of Olympic Winte...</td>\n",
       "      <td>The statistic shows the global audience of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Netflix : net income 2000 to 2019: Year|2019|x...</td>\n",
       "      <td>Video streaming giant Netflix had a total net ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Google : quarterly net income 2003 to 2015: Fi...</td>\n",
       "      <td>This timeline shows Google 's quarterly net in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Consumer spending in the United Kingdom ( UK )...</td>\n",
       "      <td>This statistic shows total domestic consumptio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  \\\n",
       "0  Light truck sales in the United States 1980 to...   \n",
       "1  Global TV audience/viewership of Olympic Winte...   \n",
       "2  Netflix : net income 2000 to 2019: Year|2019|x...   \n",
       "3  Google : quarterly net income 2003 to 2015: Fi...   \n",
       "4  Consumer spending in the United Kingdom ( UK )...   \n",
       "\n",
       "                                             summary  \n",
       "0  Light truck retail sales in the United States ...  \n",
       "1  The statistic shows the global audience of the...  \n",
       "2  Video streaming giant Netflix had a total net ...  \n",
       "3  This timeline shows Google 's quarterly net in...  \n",
       "4  This statistic shows total domestic consumptio...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "title_file = '../Chart2Text/data/valid/validTitle.txt'\n",
    "data_file = '../Chart2Text/data/valid/validData.txt'\n",
    "summary_file = '../Chart2Text/data/valid/validOriginalSummary.txt'\n",
    "\n",
    "# Load the first 50 lines of each file\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    lines = [line.strip() for line in lines]\n",
    "    return pd.DataFrame(lines, columns=['data'])\n",
    "\n",
    "# Đọc dữ liệu từ các file\n",
    "title_df = read_txt_file(title_file)\n",
    "data_df = read_txt_file(data_file)\n",
    "summary_df = read_txt_file(summary_file)\n",
    "\n",
    "# Ghép cột title và data\n",
    "combined_data = title_df['data'] + \": \" + data_df['data']\n",
    "\n",
    "# Tạo DataFrame mới từ cột data ghép và summary\n",
    "combined_df = pd.DataFrame({\n",
    "    'data': combined_data,\n",
    "    'summary': summary_df['data']\n",
    "})\n",
    "\n",
    "\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>summary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Countries with the lowest fertility rate globa...</td>\n",
       "      <td>Light truck retail sales in the United States ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Expenditure of affluent U.S. households on fee...</td>\n",
       "      <td>The statistic shows the global audience of the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Quarterly average daily rate in hotels in New ...</td>\n",
       "      <td>Video streaming giant Netflix had a total net ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Population age structure in metropolitan areas...</td>\n",
       "      <td>This timeline shows Google 's quarterly net in...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Average retail price for white sugar in Canada...</td>\n",
       "      <td>This statistic shows total domestic consumptio...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  \\\n",
       "0  Countries with the lowest fertility rate globa...   \n",
       "1  Expenditure of affluent U.S. households on fee...   \n",
       "2  Quarterly average daily rate in hotels in New ...   \n",
       "3  Population age structure in metropolitan areas...   \n",
       "4  Average retail price for white sugar in Canada...   \n",
       "\n",
       "                                             summary  \n",
       "0  Light truck retail sales in the United States ...  \n",
       "1  The statistic shows the global audience of the...  \n",
       "2  Video streaming giant Netflix had a total net ...  \n",
       "3  This timeline shows Google 's quarterly net in...  \n",
       "4  This statistic shows total domestic consumptio...  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# File paths\n",
    "title_file = '../Chart2Text/data/test/testTitle.txt'\n",
    "data_file = '../Chart2Text/data/test/testData.txt'\n",
    "summary_file = '../Chart2Text/data/test/testOriginalSummary.txt'\n",
    "\n",
    "def read_txt_file(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        lines = file.readlines()\n",
    "    lines = [line.strip() for line in lines]\n",
    "    return pd.DataFrame(lines, columns=['data'])\n",
    "\n",
    "# Đọc dữ liệu từ các file\n",
    "title_df = read_txt_file(title_file)\n",
    "data_df = read_txt_file(data_file)\n",
    "# summary_df = read_txt_file(summary_file)\n",
    "\n",
    "# Ghép cột title và data\n",
    "combined_data = title_df['data'] + \": \" + data_df['data']\n",
    "\n",
    "# Tạo DataFrame mới từ cột data ghép và summary\n",
    "combined_df = pd.DataFrame({\n",
    "    'data': combined_data,\n",
    "    'summary': summary_df['data']\n",
    "})\n",
    "\n",
    "\n",
    "combined_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../dataset/bart-t5/combined_data_test_bart_t5.csv'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_file_path = '../dataset/bart-t5/combined_data_test_bart_t5.csv'\n",
    "combined_df.to_csv(csv_file_path, index=False)\n",
    "\n",
    "csv_file_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
